{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ba3c8d-f69c-431c-b6d5-eed9cb645d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import re\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import deque\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18ad4cb6-322a-4204-a46b-b942aa37eb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 1. 유틸리티 함수들\n",
    "#############################################\n",
    "\n",
    "# 1. dP 정규화 함수\n",
    "def get_normalized_dP(domain_num):\n",
    "    if 1 <= domain_num <= 2000:\n",
    "        orig_dP = 0.005\n",
    "    elif 2001 <= domain_num <= 4000:\n",
    "        orig_dP = 0.0025\n",
    "    elif 4001 <= domain_num <= 6000:\n",
    "        orig_dP = 0.001\n",
    "    else:\n",
    "        raise ValueError(\"domain_num out of range\")\n",
    "    return (orig_dP - 0.001) / (0.005 - 0.001)\n",
    "\n",
    "# 2. Signed Distance Field (SDF)\n",
    "def create_signed_sdf(grid):\n",
    "    rows, cols = grid.shape\n",
    "    seeds = []\n",
    "    dirs = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            for di, dj in dirs:\n",
    "                ni, nj = i+di, j+dj\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    if grid[ni, nj] != grid[i, j]:\n",
    "                        seeds.append((i, j))\n",
    "                        break\n",
    "    dist = np.full((rows, cols), -1, dtype=np.int32)\n",
    "    q = deque()\n",
    "    for (i, j) in seeds:\n",
    "        dist[i, j] = 0\n",
    "        q.append((i, j))\n",
    "    while q:\n",
    "        i, j = q.popleft()\n",
    "        for di, dj in dirs:\n",
    "            ni, nj = i+di, j+dj\n",
    "            if 0 <= ni < rows and 0 <= nj < cols and dist[ni, nj] == -1:\n",
    "                dist[ni, nj] = dist[i, j] + 1\n",
    "                q.append((ni, nj))\n",
    "    sign = np.where(grid == 0, 1.0, -1.0)\n",
    "    sdf = (dist.astype(np.float32) + 0.5) * sign\n",
    "    return sdf# 1. dP 정규화 함수\n",
    "def get_normalized_dP(domain_num):\n",
    "    if 1 <= domain_num <= 2000:\n",
    "        orig_dP = 0.005\n",
    "    elif 2001 <= domain_num <= 4000:\n",
    "        orig_dP = 0.0025\n",
    "    elif 4001 <= domain_num <= 6000:\n",
    "        orig_dP = 0.001\n",
    "    else:\n",
    "        raise ValueError(\"domain_num out of range\")\n",
    "    return (orig_dP - 0.001) / (0.005 - 0.001)\n",
    "\n",
    "# 2. Signed Distance Field (SDF)\n",
    "def create_signed_sdf(grid):\n",
    "    rows, cols = grid.shape\n",
    "    seeds = []\n",
    "    dirs = [(-1,0),(1,0),(0,-1),(0,1)]\n",
    "    for i in range(rows):\n",
    "        for j in range(cols):\n",
    "            for di, dj in dirs:\n",
    "                ni, nj = i+di, j+dj\n",
    "                if 0 <= ni < rows and 0 <= nj < cols:\n",
    "                    if grid[ni, nj] != grid[i, j]:\n",
    "                        seeds.append((i, j))\n",
    "                        break\n",
    "    dist = np.full((rows, cols), -1, dtype=np.int32)\n",
    "    q = deque()\n",
    "    for (i, j) in seeds:\n",
    "        dist[i, j] = 0\n",
    "        q.append((i, j))\n",
    "    while q:\n",
    "        i, j = q.popleft()\n",
    "        for di, dj in dirs:\n",
    "            ni, nj = i+di, j+dj\n",
    "            if 0 <= ni < rows and 0 <= nj < cols and dist[ni, nj] == -1:\n",
    "                dist[ni, nj] = dist[i, j] + 1\n",
    "                q.append((ni, nj))\n",
    "    sign = np.where(grid == 0, 1.0, -1.0)\n",
    "    sdf = (dist.astype(np.float32) + 0.5) * sign\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2244174c-81d5-4e3d-9d24-5dd9dbd0f176",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 2. 데이터 로드 및 전처리 함수들\n",
    "#############################################\n",
    "\n",
    "def load_velocity_data(npz_dir, nx=64, ny=148):\n",
    "    \"\"\"\n",
    "    npz_dir에 있는 v*.npz 파일을 모두 불러서\n",
    "    각 도메인별로 dict를 만듦\n",
    "    key: 'vel' (velocity), 'mask' (이진화), 'domain_num', 'dP'\n",
    "    \"\"\"\n",
    "    v_files = sorted(glob.glob(os.path.join(npz_dir, \"v*.npz\")),\n",
    "                     key=lambda x: int(re.search(r\"v(\\d+)\\.npz\", os.path.basename(x)).group(1)))\n",
    "    data_list = []\n",
    "    for v_file in v_files:\n",
    "        m_obj = re.search(r\"v(\\d+)\\.npz\", os.path.basename(v_file))\n",
    "        if m_obj is None:\n",
    "            continue\n",
    "        domain_num = int(m_obj.group(1))\n",
    "        m_file = os.path.join(npz_dir, f\"m{domain_num}.npz\")\n",
    "        if not os.path.exists(m_file):\n",
    "            continue\n",
    "        with np.load(v_file) as v_npz:\n",
    "            # velocity 불러오기\n",
    "            if 'vel' in v_npz:\n",
    "                vel = v_npz['vel']      # shape (64,148,2) or flat\n",
    "                if vel.ndim == 1:  # flatten된 경우\n",
    "                    n_elements = nx * ny\n",
    "                    x_data = vel[:n_elements].reshape((nx, ny))\n",
    "                    y_data = vel[n_elements:].reshape((nx, ny))\n",
    "                    vel = np.stack([x_data, y_data], axis=-1)\n",
    "            else:\n",
    "                raise ValueError(f\"Key 'vel' not in {v_file}\")\n",
    "        with np.load(m_file) as m_npz:\n",
    "            if 'mask' in m_npz:\n",
    "                mask = m_npz['mask']\n",
    "                if mask.ndim == 1:\n",
    "                    mask = mask.reshape((nx, ny))\n",
    "                elif mask.ndim == 3:\n",
    "                    mask = mask[0]\n",
    "                mask = (mask > 0.5).astype(int)  # 2진화\n",
    "            else:\n",
    "                raise ValueError(f\"Key 'mask' not in {m_file}\")\n",
    "        dP = get_normalized_dP(domain_num)\n",
    "        data_list.append({'vel': vel, 'mask': mask, 'domain_num': domain_num, 'dP': dP})\n",
    "    return data_list\n",
    "\n",
    "def process_velocity_domain(sample, nx=64, ny=148):\n",
    "    domain_num = sample['domain_num']\n",
    "    # 1. Branch1: mask\n",
    "    branch1_input = sample['mask'].reshape((1, nx, ny))\n",
    "    # 2. Branch2: dP (정규화된 값)\n",
    "    branch2_input = np.array([[sample['dP']]], dtype=np.float32)  # shape [1,1]\n",
    "    # 3. SDF + 정규화\n",
    "    sdf = create_signed_sdf(sample['mask'])\n",
    "    sdf_flat = sdf.flatten().astype(np.float32)\n",
    "    sdf_min, sdf_max = sdf_flat.min(), sdf_flat.max()\n",
    "    sdf_norm = (sdf_flat - sdf_min) / (sdf_max - sdf_min + 1e-8)  # [0,1] 정규화\n",
    "\n",
    "    # 4. Trunk input [x, y, SDF]\n",
    "    x_coords = np.arange(nx, dtype=np.float32)\n",
    "    y_coords = np.arange(ny, dtype=np.float32)\n",
    "    X, Y = np.meshgrid(x_coords, y_coords, indexing=\"ij\")\n",
    "    x_flat = X.flatten()\n",
    "    y_flat = Y.flatten()\n",
    "    trunk_query = np.stack([x_flat, y_flat, sdf_norm], axis=1)   # (L,3)\n",
    "    trunk_inputs = trunk_query[np.newaxis, ...]                  # (1, L, 3)\n",
    "\n",
    "    # 5. Target: velocity field 정규화\n",
    "    vel = sample['vel'].astype(np.float32)\n",
    "    u_x, u_y = vel[..., 0], vel[..., 1]\n",
    "    u_x_min, u_x_max = u_x.min(), u_x.max()\n",
    "    u_y_min, u_y_max = u_y.min(), u_y.max()\n",
    "    epsilon = 1e-8\n",
    "    target_norm = np.empty_like(vel)\n",
    "    target_norm[..., 0] = (u_x - u_x_min) / (u_x_max - u_x_min + epsilon)\n",
    "    target_norm[..., 1] = (u_y - u_y_min) / (u_y_max - u_y_min + epsilon)\n",
    "\n",
    "    # 6. norm_params: SDF min/max, velocity min/max\n",
    "    norm_params = {\n",
    "        'u_x_min': u_x_min, 'u_x_max': u_x_max,\n",
    "        'u_y_min': u_y_min, 'u_y_max': u_y_max,\n",
    "        'sdf_min': sdf_min, 'sdf_max': sdf_max\n",
    "    }\n",
    "\n",
    "    return domain_num, branch1_input, branch2_input, trunk_inputs, target_norm, norm_params\n",
    "\n",
    "\n",
    "def build_velocity_dataset(domain_list, nx=64, ny=148):\n",
    "    branch1_list, branch2_list, trunk_list, target_list, norm_params_list = [], [], [], [], []\n",
    "    for d in domain_list:\n",
    "        _, b1, b2, t, y, p = process_velocity_domain(d, nx, ny)\n",
    "        branch1_list.append(b1)\n",
    "        branch2_list.append(b2)\n",
    "        trunk_list.append(t)\n",
    "        target_list.append(y)\n",
    "        norm_params_list.append(p)\n",
    "    return branch1_list, branch2_list, trunk_list, target_list, norm_params_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6f09820-135b-4679-a122-bae59a98cf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "npz_dir = \"/home/yehoon/npz/amv/delta_P/delta_P_data\"\n",
    "all_domains = load_velocity_data(npz_dir)\n",
    "\n",
    "# dP별 그룹 분리\n",
    "group1 = [d for d in all_domains if 1 <= d['domain_num'] <= 2000]\n",
    "group2 = [d for d in all_domains if 2001 <= d['domain_num'] <= 4000]\n",
    "group3 = [d for d in all_domains if 4001 <= d['domain_num'] <= 6000]\n",
    "\n",
    "def split_group(group, train_ratio=0.9):\n",
    "    n = len(group)\n",
    "    n_train = int(n * train_ratio)\n",
    "    indices = np.random.permutation(n)\n",
    "    train_idx, test_idx = indices[:n_train], indices[n_train:]\n",
    "    train = [group[i] for i in train_idx]\n",
    "    test  = [group[i] for i in test_idx]\n",
    "    return train, test\n",
    "\n",
    "# 각 그룹별로 나누기 (seed 고정 권장)\n",
    "np.random.seed(42)\n",
    "train_g1, test_g1 = split_group(group1, train_ratio=0.9)\n",
    "train_g2, test_g2 = split_group(group2, train_ratio=0.9)\n",
    "train_g3, test_g3 = split_group(group3, train_ratio=0.9)\n",
    "\n",
    "# 합치기\n",
    "train_domains = train_g1 + train_g2 + train_g3\n",
    "test_domains  = test_g1  + test_g2  + test_g3\n",
    "\n",
    "# 이후는 그대로...\n",
    "train_b1, train_b2, train_t, train_y, train_p = build_velocity_dataset(train_domains)\n",
    "test_b1, test_b2, test_t, test_y, test_p = build_velocity_dataset(test_domains)\n",
    "\n",
    "train_branch1 = torch.tensor(np.stack(train_b1), dtype=torch.float32)\n",
    "train_branch2 = torch.tensor(np.stack(train_b2), dtype=torch.float32)\n",
    "train_trunk   = torch.tensor(np.stack(train_t), dtype=torch.float32)\n",
    "train_target  = torch.tensor(np.stack(train_y), dtype=torch.float32)\n",
    "\n",
    "test_branch1  = torch.tensor(np.stack(test_b1), dtype=torch.float32)\n",
    "test_branch2  = torch.tensor(np.stack(test_b2), dtype=torch.float32)\n",
    "test_trunk    = torch.tensor(np.stack(test_t), dtype=torch.float32)\n",
    "test_target   = torch.tensor(np.stack(test_y), dtype=torch.float32)\n",
    "\n",
    "train_dataset = TensorDataset(train_branch1, train_branch2, train_trunk, train_target)\n",
    "test_dataset  = TensorDataset(test_branch1, test_branch2, test_trunk, test_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "23c51bb1-9142-42d9-b238-60196ed826c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 4. 수정된 모델 구성 – VelocityDeepONet\n",
    "#############################################\n",
    "\n",
    "class BasicCNN(nn.Module):\n",
    "    def __init__(self, in_channels, out_dim):\n",
    "        super().__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, 16, 3, 1, 1), nn.SiLU(), nn.AvgPool2d(2),\n",
    "            nn.Conv2d(16, 32, 3, 1, 1), nn.SiLU(), nn.AvgPool2d(2),\n",
    "            nn.Conv2d(32, 64, 3, 1, 1), nn.SiLU(), nn.AvgPool2d(2)\n",
    "        )\n",
    "        self.fc = nn.Linear(64 * 8 * 18, 2*out_dim)  # (u_x, u_y 각각 out_dim)\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)  # [N, 2*out_dim]\n",
    "\n",
    "# Branch2: dP(스칼라) → MLP → [N, 2*out_dim]\n",
    "class dPMLP(nn.Module):\n",
    "    def __init__(self, in_dim=1, out_dim=80, hidden_dim=80, num_layers=3):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.SiLU()]\n",
    "        for _ in range(num_layers-2):\n",
    "            layers += [nn.Linear(hidden_dim, hidden_dim), nn.SiLU()]\n",
    "        layers += [nn.Linear(hidden_dim, 2*out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)  # [N, 2*out_dim]\n",
    "\n",
    "# Trunk: (x, y, SDF) → MLP → [N, L, 2, out_dim]\n",
    "def create_trunk_net(trunk_in_dim, out_dim, num_layers=6, width=80):\n",
    "    layers = [nn.Linear(trunk_in_dim, width), nn.SiLU()]\n",
    "    for _ in range(num_layers-2):\n",
    "        layers += [nn.Linear(width, width), nn.SiLU()]\n",
    "    layers += [nn.Linear(width, 2*out_dim)]  # (u_x, u_y 각각 out_dim)\n",
    "    return nn.Sequential(*layers)\n",
    "\n",
    "# dP 조건부 VelocityDeepONet\n",
    "class VelocityDeepONetDP(nn.Module):\n",
    "    def __init__(self, branch1_in_dim=1, branch2_in_dim=1, trunk_in_dim=3,\n",
    "                 out_dim=100, num_layers=6, width=80, nx=64, ny=148):\n",
    "        super().__init__()\n",
    "        self.branch1_net = BasicCNN(branch1_in_dim, out_dim)\n",
    "        self.branch2_net = dPMLP(branch2_in_dim, out_dim, hidden_dim=width, num_layers=3)\n",
    "        self.trunk_net = create_trunk_net(trunk_in_dim, out_dim, num_layers, width)\n",
    "        self.bias = nn.Parameter(torch.zeros(2))\n",
    "        self.nx, self.ny = nx, ny\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "    def forward(self, branch1_input, branch2_input, trunk_input):\n",
    "        N, T, L, D = trunk_input.shape\n",
    "        trunk_flat = trunk_input.view(-1, D)\n",
    "        trunk_out = self.trunk_net(trunk_flat)\n",
    "        trunk_out = trunk_out.view(N, T, L, 2, self.out_dim)\n",
    "    \n",
    "        branch1_out = self.branch1_net(branch1_input)   # (N, 2*out_dim)\n",
    "        branch2_out = self.branch2_net(branch2_input)   # (N, 2*out_dim)여야 한다!\n",
    "\n",
    "        if branch2_out.dim() > 2:\n",
    "            branch2_out = branch2_out.squeeze(1)\n",
    "\n",
    "        branch_out = branch1_out * branch2_out          # (N, 2*out_dim)\n",
    "        branch_out = branch_out.view(N, 2, self.out_dim)\n",
    "        branch_out = branch_out.unsqueeze(1).unsqueeze(2)  # (N,1,1,2,out_dim)\n",
    "    \n",
    "        out = torch.sum(branch_out * trunk_out, dim=-1) + self.bias\n",
    "        out = out.view(N, self.nx, self.ny, 2)\n",
    "        return out\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad6b6f5f-9516-4daa-a676-fb44780abd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 5. 학습 및 평가 함수\n",
    "#############################################\n",
    "\n",
    "def train_model(model, train_dataset, test_dataset, num_epochs=100, lr=0.001, batch_size=25, patience=15):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset,  batch_size=batch_size, shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.HuberLoss(delta=1.0)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=10, delta=1e-5, verbose=False):\n",
    "            self.patience = patience\n",
    "            self.delta = delta\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_loss = None\n",
    "            self.early_stop = False\n",
    "            self.best_model_state = None\n",
    "        def __call__(self, val_loss, model):\n",
    "            if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "                self.best_model_state = model.state_dict()\n",
    "                if self.verbose:\n",
    "                    print(f\"Validation loss decreased. New best loss: {val_loss:.6f}\")\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.verbose:\n",
    "                    print(f\"No improvement: {self.counter}/{self.patience}\")\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=patience, delta=1e-5, verbose=True)\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- training ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for b1, b2, t, y in train_loader:\n",
    "            b1, b2, t, y = b1.cuda(), b2.cuda(), t.cuda(), y.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                preds = model(b1, b2, t)\n",
    "                loss = criterion(preds, y)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_train_loss += loss.item()\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- validation ---\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for b1, b2, t, y in test_loader:\n",
    "                b1, b2, t, y = b1.cuda(), b2.cuda(), t.cuda(), y.cuda()\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    preds = model(b1, b2, t)\n",
    "                    loss = criterion(preds, y)\n",
    "                running_test_loss += loss.item()\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train Loss: {avg_train_loss:.6f}, Test Loss: {avg_test_loss:.6f}\")\n",
    "\n",
    "        early_stopping(avg_test_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Restoring best model state.\")\n",
    "            model.load_state_dict(early_stopping.best_model_state)\n",
    "            break\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a93349e6-bf5d-48be-8654-ab09958b1fb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1117109/2007051620.py:12: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler()\n",
      "/tmp/ipykernel_1117109/2007051620.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "/tmp/ipykernel_1117109/2007051620.py:64: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500] Train Loss: 0.014764, Test Loss: 0.010798\n",
      "Validation loss decreased. New best loss: 0.010798\n",
      "Epoch [2/500] Train Loss: 0.011026, Test Loss: 0.010569\n",
      "Validation loss decreased. New best loss: 0.010569\n",
      "Epoch [3/500] Train Loss: 0.010676, Test Loss: 0.010743\n",
      "No improvement: 1/15\n",
      "Epoch [4/500] Train Loss: 0.010328, Test Loss: 0.010998\n",
      "No improvement: 2/15\n",
      "Epoch [5/500] Train Loss: 0.010058, Test Loss: 0.010040\n",
      "Validation loss decreased. New best loss: 0.010040\n",
      "Epoch [6/500] Train Loss: 0.009919, Test Loss: 0.009958\n",
      "Validation loss decreased. New best loss: 0.009958\n",
      "Epoch [7/500] Train Loss: 0.009749, Test Loss: 0.010245\n",
      "No improvement: 1/15\n",
      "Epoch [8/500] Train Loss: 0.009401, Test Loss: 0.009427\n",
      "Validation loss decreased. New best loss: 0.009427\n",
      "Epoch [9/500] Train Loss: 0.009037, Test Loss: 0.009291\n",
      "Validation loss decreased. New best loss: 0.009291\n",
      "Epoch [10/500] Train Loss: 0.008669, Test Loss: 0.008910\n",
      "Validation loss decreased. New best loss: 0.008910\n",
      "Epoch [11/500] Train Loss: 0.008354, Test Loss: 0.008780\n",
      "Validation loss decreased. New best loss: 0.008780\n",
      "Epoch [12/500] Train Loss: 0.008045, Test Loss: 0.008441\n",
      "Validation loss decreased. New best loss: 0.008441\n",
      "Epoch [13/500] Train Loss: 0.007604, Test Loss: 0.009171\n",
      "No improvement: 1/15\n",
      "Epoch [14/500] Train Loss: 0.007265, Test Loss: 0.008265\n",
      "Validation loss decreased. New best loss: 0.008265\n",
      "Epoch [15/500] Train Loss: 0.007007, Test Loss: 0.008028\n",
      "Validation loss decreased. New best loss: 0.008028\n",
      "Epoch [16/500] Train Loss: 0.006635, Test Loss: 0.007246\n",
      "Validation loss decreased. New best loss: 0.007246\n",
      "Epoch [17/500] Train Loss: 0.006051, Test Loss: 0.006574\n",
      "Validation loss decreased. New best loss: 0.006574\n",
      "Epoch [18/500] Train Loss: 0.005546, Test Loss: 0.006423\n",
      "Validation loss decreased. New best loss: 0.006423\n",
      "Epoch [19/500] Train Loss: 0.005134, Test Loss: 0.005796\n",
      "Validation loss decreased. New best loss: 0.005796\n",
      "Epoch [20/500] Train Loss: 0.004758, Test Loss: 0.005670\n",
      "Validation loss decreased. New best loss: 0.005670\n",
      "Epoch [21/500] Train Loss: 0.004489, Test Loss: 0.005484\n",
      "Validation loss decreased. New best loss: 0.005484\n",
      "Epoch [22/500] Train Loss: 0.004154, Test Loss: 0.004734\n",
      "Validation loss decreased. New best loss: 0.004734\n",
      "Epoch [23/500] Train Loss: 0.003722, Test Loss: 0.004510\n",
      "Validation loss decreased. New best loss: 0.004510\n",
      "Epoch [24/500] Train Loss: 0.003502, Test Loss: 0.004465\n",
      "Validation loss decreased. New best loss: 0.004465\n",
      "Epoch [25/500] Train Loss: 0.003195, Test Loss: 0.003759\n",
      "Validation loss decreased. New best loss: 0.003759\n",
      "Epoch [26/500] Train Loss: 0.002887, Test Loss: 0.003721\n",
      "Validation loss decreased. New best loss: 0.003721\n",
      "Epoch [27/500] Train Loss: 0.002717, Test Loss: 0.003198\n",
      "Validation loss decreased. New best loss: 0.003198\n",
      "Epoch [28/500] Train Loss: 0.002560, Test Loss: 0.003063\n",
      "Validation loss decreased. New best loss: 0.003063\n",
      "Epoch [29/500] Train Loss: 0.002309, Test Loss: 0.002848\n",
      "Validation loss decreased. New best loss: 0.002848\n",
      "Epoch [30/500] Train Loss: 0.002229, Test Loss: 0.002970\n",
      "No improvement: 1/15\n",
      "Epoch [31/500] Train Loss: 0.002103, Test Loss: 0.002591\n",
      "Validation loss decreased. New best loss: 0.002591\n",
      "Epoch [32/500] Train Loss: 0.002041, Test Loss: 0.002479\n",
      "Validation loss decreased. New best loss: 0.002479\n",
      "Epoch [33/500] Train Loss: 0.001846, Test Loss: 0.002376\n",
      "Validation loss decreased. New best loss: 0.002376\n",
      "Epoch [34/500] Train Loss: 0.001770, Test Loss: 0.002200\n",
      "Validation loss decreased. New best loss: 0.002200\n",
      "Epoch [35/500] Train Loss: 0.001697, Test Loss: 0.002084\n",
      "Validation loss decreased. New best loss: 0.002084\n",
      "Epoch [36/500] Train Loss: 0.001605, Test Loss: 0.001980\n",
      "Validation loss decreased. New best loss: 0.001980\n",
      "Epoch [37/500] Train Loss: 0.001487, Test Loss: 0.001855\n",
      "Validation loss decreased. New best loss: 0.001855\n",
      "Epoch [38/500] Train Loss: 0.001477, Test Loss: 0.001775\n",
      "Validation loss decreased. New best loss: 0.001775\n",
      "Epoch [39/500] Train Loss: 0.001378, Test Loss: 0.001720\n",
      "Validation loss decreased. New best loss: 0.001720\n",
      "Epoch [40/500] Train Loss: 0.001394, Test Loss: 0.001707\n",
      "Validation loss decreased. New best loss: 0.001707\n",
      "Epoch [41/500] Train Loss: 0.001391, Test Loss: 0.001618\n",
      "Validation loss decreased. New best loss: 0.001618\n",
      "Epoch [42/500] Train Loss: 0.001303, Test Loss: 0.001599\n",
      "Validation loss decreased. New best loss: 0.001599\n",
      "Epoch [43/500] Train Loss: 0.001228, Test Loss: 0.001589\n",
      "No improvement: 1/15\n",
      "Epoch [44/500] Train Loss: 0.001187, Test Loss: 0.001455\n",
      "Validation loss decreased. New best loss: 0.001455\n",
      "Epoch [45/500] Train Loss: 0.001163, Test Loss: 0.001608\n",
      "No improvement: 1/15\n",
      "Epoch [46/500] Train Loss: 0.001249, Test Loss: 0.001625\n",
      "No improvement: 2/15\n",
      "Epoch [47/500] Train Loss: 0.001203, Test Loss: 0.001357\n",
      "Validation loss decreased. New best loss: 0.001357\n",
      "Epoch [48/500] Train Loss: 0.001080, Test Loss: 0.001377\n",
      "No improvement: 1/15\n",
      "Epoch [49/500] Train Loss: 0.001082, Test Loss: 0.001304\n",
      "Validation loss decreased. New best loss: 0.001304\n",
      "Epoch [50/500] Train Loss: 0.001027, Test Loss: 0.001383\n",
      "No improvement: 1/15\n",
      "Epoch [51/500] Train Loss: 0.001036, Test Loss: 0.001294\n",
      "Validation loss decreased. New best loss: 0.001294\n",
      "Epoch [52/500] Train Loss: 0.000938, Test Loss: 0.001435\n",
      "No improvement: 1/15\n",
      "Epoch [53/500] Train Loss: 0.000968, Test Loss: 0.001184\n",
      "Validation loss decreased. New best loss: 0.001184\n",
      "Epoch [54/500] Train Loss: 0.000946, Test Loss: 0.001214\n",
      "No improvement: 1/15\n",
      "Epoch [55/500] Train Loss: 0.000874, Test Loss: 0.001114\n",
      "Validation loss decreased. New best loss: 0.001114\n",
      "Epoch [56/500] Train Loss: 0.000843, Test Loss: 0.001082\n",
      "Validation loss decreased. New best loss: 0.001082\n",
      "Epoch [57/500] Train Loss: 0.000854, Test Loss: 0.001104\n",
      "No improvement: 1/15\n",
      "Epoch [58/500] Train Loss: 0.000842, Test Loss: 0.001067\n",
      "Validation loss decreased. New best loss: 0.001067\n",
      "Epoch [59/500] Train Loss: 0.000819, Test Loss: 0.001061\n",
      "No improvement: 1/15\n",
      "Epoch [60/500] Train Loss: 0.000791, Test Loss: 0.001096\n",
      "No improvement: 2/15\n",
      "Epoch [61/500] Train Loss: 0.000875, Test Loss: 0.001085\n",
      "No improvement: 3/15\n",
      "Epoch [62/500] Train Loss: 0.000799, Test Loss: 0.001031\n",
      "Validation loss decreased. New best loss: 0.001031\n",
      "Epoch [63/500] Train Loss: 0.000764, Test Loss: 0.001050\n",
      "No improvement: 1/15\n",
      "Epoch [64/500] Train Loss: 0.000761, Test Loss: 0.000967\n",
      "Validation loss decreased. New best loss: 0.000967\n",
      "Epoch [65/500] Train Loss: 0.000816, Test Loss: 0.001024\n",
      "No improvement: 1/15\n",
      "Epoch [66/500] Train Loss: 0.000744, Test Loss: 0.000935\n",
      "Validation loss decreased. New best loss: 0.000935\n",
      "Epoch [67/500] Train Loss: 0.000704, Test Loss: 0.000910\n",
      "Validation loss decreased. New best loss: 0.000910\n",
      "Epoch [68/500] Train Loss: 0.000676, Test Loss: 0.000914\n",
      "No improvement: 1/15\n",
      "Epoch [69/500] Train Loss: 0.000682, Test Loss: 0.000947\n",
      "No improvement: 2/15\n",
      "Epoch [70/500] Train Loss: 0.000677, Test Loss: 0.000930\n",
      "No improvement: 3/15\n",
      "Epoch [71/500] Train Loss: 0.000684, Test Loss: 0.000937\n",
      "No improvement: 4/15\n",
      "Epoch [72/500] Train Loss: 0.000680, Test Loss: 0.000892\n",
      "Validation loss decreased. New best loss: 0.000892\n",
      "Epoch [73/500] Train Loss: 0.000657, Test Loss: 0.000942\n",
      "No improvement: 1/15\n",
      "Epoch [74/500] Train Loss: 0.000635, Test Loss: 0.000804\n",
      "Validation loss decreased. New best loss: 0.000804\n",
      "Epoch [75/500] Train Loss: 0.000627, Test Loss: 0.000834\n",
      "No improvement: 1/15\n",
      "Epoch [76/500] Train Loss: 0.000615, Test Loss: 0.000843\n",
      "No improvement: 2/15\n",
      "Epoch [77/500] Train Loss: 0.000621, Test Loss: 0.000808\n",
      "No improvement: 3/15\n",
      "Epoch [78/500] Train Loss: 0.000570, Test Loss: 0.000803\n",
      "No improvement: 4/15\n",
      "Epoch [79/500] Train Loss: 0.000567, Test Loss: 0.000791\n",
      "Validation loss decreased. New best loss: 0.000791\n",
      "Epoch [80/500] Train Loss: 0.000543, Test Loss: 0.000932\n",
      "No improvement: 1/15\n",
      "Epoch [81/500] Train Loss: 0.000553, Test Loss: 0.000777\n",
      "Validation loss decreased. New best loss: 0.000777\n",
      "Epoch [82/500] Train Loss: 0.000594, Test Loss: 0.000823\n",
      "No improvement: 1/15\n",
      "Epoch [83/500] Train Loss: 0.000584, Test Loss: 0.000753\n",
      "Validation loss decreased. New best loss: 0.000753\n",
      "Epoch [84/500] Train Loss: 0.000538, Test Loss: 0.000766\n",
      "No improvement: 1/15\n",
      "Epoch [85/500] Train Loss: 0.000556, Test Loss: 0.000759\n",
      "No improvement: 2/15\n",
      "Epoch [86/500] Train Loss: 0.000545, Test Loss: 0.000733\n",
      "Validation loss decreased. New best loss: 0.000733\n",
      "Epoch [87/500] Train Loss: 0.000495, Test Loss: 0.000689\n",
      "Validation loss decreased. New best loss: 0.000689\n",
      "Epoch [88/500] Train Loss: 0.000513, Test Loss: 0.000702\n",
      "No improvement: 1/15\n",
      "Epoch [89/500] Train Loss: 0.000508, Test Loss: 0.000719\n",
      "No improvement: 2/15\n",
      "Epoch [90/500] Train Loss: 0.000485, Test Loss: 0.000690\n",
      "No improvement: 3/15\n",
      "Epoch [91/500] Train Loss: 0.000515, Test Loss: 0.000697\n",
      "No improvement: 4/15\n",
      "Epoch [92/500] Train Loss: 0.000514, Test Loss: 0.000763\n",
      "No improvement: 5/15\n",
      "Epoch [93/500] Train Loss: 0.000502, Test Loss: 0.000685\n",
      "No improvement: 6/15\n",
      "Epoch [94/500] Train Loss: 0.000453, Test Loss: 0.000677\n",
      "Validation loss decreased. New best loss: 0.000677\n",
      "Epoch [95/500] Train Loss: 0.000459, Test Loss: 0.000657\n",
      "Validation loss decreased. New best loss: 0.000657\n",
      "Epoch [96/500] Train Loss: 0.000435, Test Loss: 0.000703\n",
      "No improvement: 1/15\n",
      "Epoch [97/500] Train Loss: 0.000459, Test Loss: 0.000677\n",
      "No improvement: 2/15\n",
      "Epoch [98/500] Train Loss: 0.000473, Test Loss: 0.000664\n",
      "No improvement: 3/15\n",
      "Epoch [99/500] Train Loss: 0.000433, Test Loss: 0.000613\n",
      "Validation loss decreased. New best loss: 0.000613\n",
      "Epoch [100/500] Train Loss: 0.000450, Test Loss: 0.000700\n",
      "No improvement: 1/15\n",
      "Epoch [101/500] Train Loss: 0.000451, Test Loss: 0.000681\n",
      "No improvement: 2/15\n",
      "Epoch [102/500] Train Loss: 0.000450, Test Loss: 0.000758\n",
      "No improvement: 3/15\n",
      "Epoch [103/500] Train Loss: 0.000454, Test Loss: 0.000652\n",
      "No improvement: 4/15\n",
      "Epoch [104/500] Train Loss: 0.000427, Test Loss: 0.000600\n",
      "Validation loss decreased. New best loss: 0.000600\n",
      "Epoch [105/500] Train Loss: 0.000390, Test Loss: 0.000576\n",
      "Validation loss decreased. New best loss: 0.000576\n",
      "Epoch [106/500] Train Loss: 0.000391, Test Loss: 0.000621\n",
      "No improvement: 1/15\n",
      "Epoch [107/500] Train Loss: 0.000410, Test Loss: 0.000610\n",
      "No improvement: 2/15\n",
      "Epoch [108/500] Train Loss: 0.000426, Test Loss: 0.000678\n",
      "No improvement: 3/15\n",
      "Epoch [109/500] Train Loss: 0.000420, Test Loss: 0.000650\n",
      "No improvement: 4/15\n",
      "Epoch [110/500] Train Loss: 0.000467, Test Loss: 0.000604\n",
      "No improvement: 5/15\n",
      "Epoch [111/500] Train Loss: 0.000404, Test Loss: 0.000589\n",
      "No improvement: 6/15\n",
      "Epoch [112/500] Train Loss: 0.000394, Test Loss: 0.000610\n",
      "No improvement: 7/15\n",
      "Epoch [113/500] Train Loss: 0.000372, Test Loss: 0.000582\n",
      "No improvement: 8/15\n",
      "Epoch [114/500] Train Loss: 0.000361, Test Loss: 0.000591\n",
      "No improvement: 9/15\n",
      "Epoch [115/500] Train Loss: 0.000401, Test Loss: 0.000636\n",
      "No improvement: 10/15\n",
      "Epoch [116/500] Train Loss: 0.000406, Test Loss: 0.000607\n",
      "No improvement: 11/15\n",
      "Epoch [117/500] Train Loss: 0.000383, Test Loss: 0.000590\n",
      "No improvement: 12/15\n",
      "Epoch [118/500] Train Loss: 0.000387, Test Loss: 0.000563\n",
      "Validation loss decreased. New best loss: 0.000563\n",
      "Epoch [119/500] Train Loss: 0.000357, Test Loss: 0.000542\n",
      "Validation loss decreased. New best loss: 0.000542\n",
      "Epoch [120/500] Train Loss: 0.000383, Test Loss: 0.000578\n",
      "No improvement: 1/15\n",
      "Epoch [121/500] Train Loss: 0.000390, Test Loss: 0.000664\n",
      "No improvement: 2/15\n",
      "Epoch [122/500] Train Loss: 0.000380, Test Loss: 0.000536\n",
      "No improvement: 3/15\n",
      "Epoch [123/500] Train Loss: 0.000334, Test Loss: 0.000519\n",
      "Validation loss decreased. New best loss: 0.000519\n",
      "Epoch [124/500] Train Loss: 0.000367, Test Loss: 0.000549\n",
      "No improvement: 1/15\n",
      "Epoch [125/500] Train Loss: 0.000379, Test Loss: 0.000584\n",
      "No improvement: 2/15\n",
      "Epoch [126/500] Train Loss: 0.000368, Test Loss: 0.000598\n",
      "No improvement: 3/15\n",
      "Epoch [127/500] Train Loss: 0.000355, Test Loss: 0.000560\n",
      "No improvement: 4/15\n",
      "Epoch [128/500] Train Loss: 0.000359, Test Loss: 0.000565\n",
      "No improvement: 5/15\n",
      "Epoch [129/500] Train Loss: 0.000349, Test Loss: 0.000544\n",
      "No improvement: 6/15\n",
      "Epoch [130/500] Train Loss: 0.000337, Test Loss: 0.000541\n",
      "No improvement: 7/15\n",
      "Epoch [131/500] Train Loss: 0.000323, Test Loss: 0.000531\n",
      "No improvement: 8/15\n",
      "Epoch [132/500] Train Loss: 0.000358, Test Loss: 0.000564\n",
      "No improvement: 9/15\n",
      "Epoch [133/500] Train Loss: 0.000341, Test Loss: 0.000531\n",
      "No improvement: 10/15\n",
      "Epoch [134/500] Train Loss: 0.000364, Test Loss: 0.000552\n",
      "No improvement: 11/15\n",
      "Epoch [135/500] Train Loss: 0.000343, Test Loss: 0.000532\n",
      "No improvement: 12/15\n",
      "Epoch [136/500] Train Loss: 0.000336, Test Loss: 0.000549\n",
      "No improvement: 13/15\n",
      "Epoch [137/500] Train Loss: 0.000317, Test Loss: 0.000519\n",
      "No improvement: 14/15\n",
      "Epoch [138/500] Train Loss: 0.000324, Test Loss: 0.000504\n",
      "Validation loss decreased. New best loss: 0.000504\n",
      "Epoch [139/500] Train Loss: 0.000315, Test Loss: 0.000488\n",
      "Validation loss decreased. New best loss: 0.000488\n",
      "Epoch [140/500] Train Loss: 0.000315, Test Loss: 0.000517\n",
      "No improvement: 1/15\n",
      "Epoch [141/500] Train Loss: 0.000323, Test Loss: 0.000589\n",
      "No improvement: 2/15\n",
      "Epoch [142/500] Train Loss: 0.000355, Test Loss: 0.000621\n",
      "No improvement: 3/15\n",
      "Epoch [143/500] Train Loss: 0.000372, Test Loss: 0.000520\n",
      "No improvement: 4/15\n",
      "Epoch [144/500] Train Loss: 0.000320, Test Loss: 0.000490\n",
      "No improvement: 5/15\n",
      "Epoch [145/500] Train Loss: 0.000289, Test Loss: 0.000498\n",
      "No improvement: 6/15\n",
      "Epoch [146/500] Train Loss: 0.000299, Test Loss: 0.000487\n",
      "No improvement: 7/15\n",
      "Epoch [147/500] Train Loss: 0.000326, Test Loss: 0.000516\n",
      "No improvement: 8/15\n",
      "Epoch [148/500] Train Loss: 0.000328, Test Loss: 0.000511\n",
      "No improvement: 9/15\n",
      "Epoch [149/500] Train Loss: 0.000319, Test Loss: 0.000506\n",
      "No improvement: 10/15\n",
      "Epoch [150/500] Train Loss: 0.000288, Test Loss: 0.000484\n",
      "No improvement: 11/15\n",
      "Epoch [151/500] Train Loss: 0.000282, Test Loss: 0.000485\n",
      "No improvement: 12/15\n",
      "Epoch [152/500] Train Loss: 0.000326, Test Loss: 0.000524\n",
      "No improvement: 13/15\n",
      "Epoch [153/500] Train Loss: 0.000331, Test Loss: 0.000519\n",
      "No improvement: 14/15\n",
      "Epoch [154/500] Train Loss: 0.000289, Test Loss: 0.000493\n",
      "No improvement: 15/15\n",
      "Early stopping triggered. Restoring best model state.\n"
     ]
    }
   ],
   "source": [
    "model = VelocityDeepONetDP(\n",
    "    branch1_in_dim=1,\n",
    "    branch2_in_dim=1,\n",
    "    trunk_in_dim=3,\n",
    "    out_dim=500,\n",
    "    num_layers=8,\n",
    "    width=500,\n",
    "    nx=64,\n",
    "    ny=148\n",
    ")\n",
    "\n",
    "# 2. 학습\n",
    "train_losses, test_losses = train_model(\n",
    "    model, train_dataset, test_dataset, num_epochs=500, lr=0.001, batch_size=25, patience=15\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e70e66ac-b814-4cb4-a43e-8c15637d2f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################\n",
    "# 후보정 및 후보정 기반 시각화 함수들 (유속)\n",
    "#############################################\n",
    "\n",
    "def apply_candidate_correction(arr, mask):\n",
    "    arr = arr.copy()\n",
    "    arr[mask < 0.5] = 0\n",
    "    return arr\n",
    "\n",
    "def inverse_normalize(arr, norm_param):\n",
    "    x = arr[..., 0] * (norm_param['u_x_max'] - norm_param['u_x_min']) + norm_param['u_x_min']\n",
    "    y = arr[..., 1] * (norm_param['u_y_max'] - norm_param['u_y_min']) + norm_param['u_y_min']\n",
    "    return np.stack([x, y], axis=-1)\n",
    "\n",
    "def inverse_normalize_sdf(normed_sdf, norm_param):\n",
    "    return normed_sdf * (norm_param['sdf_max'] - norm_param['sdf_min']) + norm_param['sdf_min']\n",
    "\n",
    "# 8. 예측/시각화 샘플\n",
    "def visualize_velocity_field(model, branch1_tensor, branch2_tensor, trunk_tensor, target_tensor, norm_params, sample_idx):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        b1 = branch1_tensor[sample_idx:sample_idx+1].to(device)\n",
    "        b2 = branch2_tensor[sample_idx:sample_idx+1].to(device)\n",
    "        t = trunk_tensor[sample_idx:sample_idx+1].to(device)\n",
    "        preds = model(b1, b2, t).cpu().numpy()[0]\n",
    "        actual = target_tensor[sample_idx].cpu().numpy()\n",
    "    preds = inverse_normalize(preds, norm_params[sample_idx])\n",
    "    actual = inverse_normalize(actual, norm_params[sample_idx])\n",
    "    mask = branch1_tensor[sample_idx, 0].cpu().numpy()\n",
    "    p_corr = apply_candidate_correction(preds, mask)\n",
    "    a_corr = apply_candidate_correction(actual, mask)\n",
    "    ux_sim, ux_pred = a_corr[..., 0], p_corr[..., 0]\n",
    "    uy_sim, uy_pred = a_corr[..., 1], p_corr[..., 1]\n",
    "    vmin_x, vmax_x = ux_sim.min(), ux_sim.max()\n",
    "    vmin_y, vmax_y = uy_sim.min(), uy_sim.max()\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(10, 10), constrained_layout=True)\n",
    "    axes[0,0].imshow(ux_sim, vmin=vmin_x, vmax=vmax_x)\n",
    "    axes[0,0].set_title('Simulation u_x')\n",
    "    im = axes[0,1].imshow(ux_pred, vmin=vmin_x, vmax=vmax_x)\n",
    "    axes[0,1].set_title('Predicted u_x')\n",
    "    fig.colorbar(im, ax=axes[0,:], orientation='vertical')\n",
    "    axes[1,0].imshow(uy_sim, vmin=vmin_y, vmax=vmax_y)\n",
    "    axes[1,0].set_title('Simulation u_y')\n",
    "    im2 = axes[1,1].imshow(uy_pred, vmin=vmin_y, vmax=vmax_y)\n",
    "    axes[1,1].set_title('Predicted u_y')\n",
    "    fig.colorbar(im2, ax=axes[1,:], orientation='vertical')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compute_errors(model, branch_tensor, trunk_tensor, target_tensor, norm_params, sample_idx):\n",
    "    \"\"\"\n",
    "    예측 및 실제를 가져와 후보정 및 역정규화 후\n",
    "    - percent_error_u/v\n",
    "    - abs_error_u/v\n",
    "    반환\n",
    "    \"\"\"\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        b = branch_tensor[sample_idx:sample_idx+1].to(device)\n",
    "        t = trunk_tensor[sample_idx:sample_idx+1].to(device)\n",
    "        pred = model(b, t).cpu().numpy()[0]\n",
    "        actual = target_tensor[sample_idx].numpy()\n",
    "\n",
    "    pred = inverse_normalize(pred, norm_params)\n",
    "    actual = inverse_normalize(actual, norm_params)\n",
    "    mask = branch_tensor[sample_idx,0].numpy()\n",
    "\n",
    "    p_corr = apply_candidate_correction(pred, mask)\n",
    "    a_corr = apply_candidate_correction(actual, mask)\n",
    "\n",
    "    eps = 1e-8\n",
    "    percent_u = ((p_corr[...,0] - a_corr[...,0]) / (np.abs(a_corr[...,0])+eps) * 100).clip(-10,10)\n",
    "    percent_v = ((p_corr[...,1] - a_corr[...,1]) / (np.abs(a_corr[...,1])+eps) * 100).clip(-10,10)\n",
    "    abs_u = np.abs(p_corr[...,0] - a_corr[...,0])\n",
    "    abs_v = np.abs(p_corr[...,1] - a_corr[...,1])\n",
    "\n",
    "    return percent_u, percent_v, abs_u, abs_v\n",
    "\n",
    "def compute_nrmse_velocity_corrected(preds, actual, mask):\n",
    "    # mask: 0(암석), 1(공극)\n",
    "    area = (mask > 0.5)\n",
    "    if area.sum() == 0:\n",
    "        return 0.0\n",
    "    pred_flat = preds[area]\n",
    "    actual_flat = actual[area]\n",
    "    rmse = np.sqrt(np.mean((pred_flat - actual_flat) ** 2))\n",
    "    denom = np.max(actual_flat) - np.min(actual_flat) + 1e-8\n",
    "    nrmse = rmse / denom\n",
    "    return nrmse\n",
    "\n",
    "\n",
    "def evaluate_sample_velocity(model, test_branch1, test_branch2, test_trunk, test_target, idx):\n",
    "    # 입력: tensor들, idx 번째 샘플\n",
    "    model.eval()\n",
    "    device = next(model.parameters()).device\n",
    "    with torch.no_grad():\n",
    "        branch1 = test_branch1[idx:idx+1].to(device)\n",
    "        branch2 = test_branch2[idx:idx+1].to(device)\n",
    "        trunk   = test_trunk[idx:idx+1].to(device)\n",
    "        target  = test_target[idx:idx+1].to(device)\n",
    "        preds = model(branch1, branch2, trunk)   # [1, 64, 148, 2]\n",
    "        preds_np = preds.cpu().numpy()[0]\n",
    "        target_np = target.cpu().numpy()[0]\n",
    "        return preds_np, target_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab693907-674b-4d98-81de-3e4411eecdcb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'visualize_results_velocity_corrected' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# 4) 2×2 필드 비교\u001b[39;00m\n\u001b[1;32m      8\u001b[0m norm_params \u001b[38;5;241m=\u001b[39m test_p[sample_idx]                           \u001b[38;5;66;03m# 도메인마다 저장해둔 정규화 파라미터\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[43mvisualize_results_velocity_corrected\u001b[49m(\n\u001b[1;32m     10\u001b[0m     model,\n\u001b[1;32m     11\u001b[0m     test_branch,    \u001b[38;5;66;03m# torch.Tensor, shape = (N,1,nx,ny)\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     test_trunk,     \u001b[38;5;66;03m# torch.Tensor, shape = (N,1,nx*ny,3)\u001b[39;00m\n\u001b[1;32m     13\u001b[0m     test_target,    \u001b[38;5;66;03m# torch.Tensor, shape = (N,nx,ny,2)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m     sample_idx,\n\u001b[1;32m     15\u001b[0m     norm_params,\n\u001b[1;32m     16\u001b[0m     save_svg\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfield_comparison.svg\u001b[39m\u001b[38;5;124m\"\u001b[39m  \u001b[38;5;66;03m# 저장을 원치 않으면 이 인자 생략\u001b[39;00m\n\u001b[1;32m     17\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'visualize_results_velocity_corrected' is not defined"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device).eval()\n",
    "\n",
    "# 3) 시각화할 샘플 인덱스\n",
    "sample_idx = 0\n",
    "\n",
    "# 4) 2×2 필드 비교\n",
    "norm_params = test_p[sample_idx]                           # 도메인마다 저장해둔 정규화 파라미터\n",
    "visualize_results_velocity_corrected(\n",
    "    model,\n",
    "    test_branch,    # torch.Tensor, shape = (N,1,nx,ny)\n",
    "    test_trunk,     # torch.Tensor, shape = (N,1,nx*ny,3)\n",
    "    test_target,    # torch.Tensor, shape = (N,nx,ny,2)\n",
    "    sample_idx,\n",
    "    norm_params,\n",
    "    save_svg=\"field_comparison.svg\"  # 저장을 원치 않으면 이 인자 생략\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609fab0d-a793-4dc1-aab1-c248f3f1415a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    b = test_branch[sample_idx:sample_idx+1].to(device)\n",
    "    t = test_trunk[sample_idx:sample_idx+1].to(device)\n",
    "    pred_field = model(b, t).cpu().numpy()[0]          # (nx,ny,2)\n",
    "actual_field = test_target[sample_idx].numpy()         # (nx,ny,2)\n",
    "mask = test_branch[sample_idx,0].numpy()               # (nx,ny), 0=광물\n",
    "\n",
    "scatter_velocity_corrected(\n",
    "    pred_field,\n",
    "    actual_field,\n",
    "    mask,\n",
    "    save_svg=\"scatter_u.png\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a4741e2-e71a-4f67-9e1d-68cd40497989",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "# 선 그래프를 그리고\n",
    "plt.plot(epochs, train_losses, label='Train Loss')\n",
    "plt.plot(epochs, test_losses,  label='Test Loss')\n",
    "\n",
    "# 로그 스케일 설정 (y축만)\n",
    "plt.yscale('log')\n",
    "\n",
    "# (원하시면 x축도 로그 스케일로)\n",
    "# plt.xscale('log')\n",
    "\n",
    "# 축 라벨, 제목, 범례, 그리드\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Loss Velocity (Log Scale)')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# SVG로 저장\n",
    "plt.savefig(\"velocity_loss_log.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd322257-4309-4afc-b9b3-f0af9008736e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "가장 오차가 작은 테스트 인덱스: 136\n",
      "해당 도메인 번호         : 167\n",
      "최소 NRMSE 값           : 0.0154\n"
     ]
    }
   ],
   "source": [
    "errors = []\n",
    "for idx in range(len(test_branch1)):\n",
    "    preds, actual = evaluate_sample_velocity(\n",
    "        model, \n",
    "        test_branch1, \n",
    "        test_branch2, \n",
    "        test_trunk, \n",
    "        test_target, \n",
    "        idx\n",
    "    )\n",
    "    mask = test_branch1[idx].cpu().numpy()[0]\n",
    "    nrmse = compute_nrmse_velocity_corrected(preds, actual, mask)\n",
    "    errors.append(nrmse)\n",
    "\n",
    "errors = np.array(errors)\n",
    "best_idx = int(np.argmin(errors))\n",
    "best_domain = test_domains[best_idx]['domain_num']\n",
    "best_nrmse = errors[best_idx]\n",
    "\n",
    "print(f\"가장 오차가 작은 테스트 인덱스: {best_idx}\")\n",
    "print(f\"해당 도메인 번호         : {best_domain}\")\n",
    "print(f\"최소 NRMSE 값           : {best_nrmse:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f024a200-e753-40b4-b3df-851643611ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x400 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_idx = 136\n",
    "\n",
    "# 1. 마스크 이미지\n",
    "mask_img = test_branch1[test_idx, 0].cpu().numpy()    # (64,148)\n",
    "\n",
    "# 2. SDF 이미지\n",
    "sdf_flat = test_trunk[test_idx, 0, :, 2].cpu().numpy()\n",
    "sdf_img = sdf_flat.reshape(mask_img.shape)\n",
    "\n",
    "# 3. 유속 벡터 (정규화 해제)\n",
    "norm_p = test_p[test_idx]\n",
    "u_x_min, u_x_max = norm_p['u_x_min'], norm_p['u_x_max']\n",
    "u_y_min, u_y_max = norm_p['u_y_min'], norm_p['u_y_max']\n",
    "\n",
    "vel_norm = test_target[test_idx].cpu().numpy()   # (64,148,2)\n",
    "u_x = vel_norm[..., 0] * (u_x_max - u_x_min) + u_x_min\n",
    "u_y = vel_norm[..., 1] * (u_y_max - u_y_min) + u_y_min\n",
    "vel_vec = np.stack([u_x, u_y], axis=-1)         # (64,148,2)\n",
    "vel_mag = np.linalg.norm(vel_vec, axis=-1)      # (64,148)\n",
    "\n",
    "# --- 시각화 ---\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "axes[0].imshow(mask_img, cmap='gray')\n",
    "axes[0].set_title(\"Mask\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "im1 = axes[1].imshow(sdf_img, cmap='coolwarm')\n",
    "axes[1].set_title(\"SDF\")\n",
    "axes[1].axis('off')\n",
    "cbar1 = plt.colorbar(im1, ax=axes[1], orientation='horizontal', shrink=1, pad=0.15, aspect=30)\n",
    "\n",
    "im2 = axes[2].imshow(vel_mag, cmap='viridis')\n",
    "axes[2].set_title(\"Velocity Magnitude\")\n",
    "axes[2].axis('off')\n",
    "cbar2 = plt.colorbar(im2, ax=axes[2], orientation='horizontal', shrink=1, pad=0.15, aspect=30)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"DON_v_dP.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f614fc-2580-499a-8d59-c4183446b37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sdf_flat.shape)\n",
    "print(\"최소값:\", sdf_flat.min())\n",
    "print(\"최대값:\", sdf_flat.max())\n",
    "print(\"평균:\", sdf_flat.mean())\n",
    "print(\"중간값:\", np.median(sdf_flat))\n",
    "print(\"앞부분 10개:\", sdf_flat[:10])\n",
    "\n",
    "print(\"0(암석) 개수:\", np.sum(mask_img==0))\n",
    "print(\"1(공극) 개수:\", np.sum(mask_img==1))\n",
    "print(\"mask_img 고유값:\", np.unique(mask_img))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7eaf04-8db6-4bad-b0f7-b052d0950433",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1) NRMSE 계산 및 분위수 샘플 추출 ---\n",
    "nrmse_list = []\n",
    "num_samples = len(test_branch)\n",
    "for idx in range(num_samples):\n",
    "    preds_norm, actual_norm = evaluate_sample_velocity(\n",
    "        model,\n",
    "        test_branch,\n",
    "        test_trunk,\n",
    "        test_target,\n",
    "        idx\n",
    "    )\n",
    "    mask = test_branch[idx].cpu().numpy()[0]\n",
    "    nrmse_list.append(compute_nrmse_velocity_corrected(preds_norm, actual_norm, mask))\n",
    "nrmse_arr = np.array(nrmse_list)\n",
    "\n",
    "best_idx  = nrmse_arr.argmin()\n",
    "worst_idx = nrmse_arr.argmax()\n",
    "sorted_idx = np.argsort(nrmse_arr)\n",
    "idx25 = sorted_idx[int(0.25 * len(sorted_idx))]\n",
    "idx50 = sorted_idx[int(0.50 * len(sorted_idx))]\n",
    "idx75 = sorted_idx[int(0.75 * len(sorted_idx))]\n",
    "sample_indices = [best_idx, idx25, idx50, idx75, worst_idx]\n",
    "row_labels     = [\"Best\", \"25%\", \"50%\", \"75%\", \"Worst\"]\n",
    "\n",
    "# --- 2) 전역 vmin/vmax 계산 (예측/실제 벡터장의 크기, 오차) ---\n",
    "mag_vals, err_vals = [], []\n",
    "for idx in sample_indices:\n",
    "    preds_norm, actual_norm = evaluate_sample_velocity(\n",
    "        model, test_branch, test_trunk, test_target, idx\n",
    "    )\n",
    "    preds_denorm  = inverse_normalize(preds_norm,  test_p[idx])\n",
    "    actual_denorm = inverse_normalize(actual_norm, test_p[idx])\n",
    "    mask = test_branch[idx].cpu().numpy()[0]\n",
    "    preds_corr  = apply_candidate_correction(preds_denorm,  mask)\n",
    "    actual_corr = apply_candidate_correction(actual_denorm, mask)\n",
    "    mag_pred = np.linalg.norm(preds_corr, axis=-1)\n",
    "    mag_act  = np.linalg.norm(actual_corr, axis=-1)\n",
    "    mag_vals.extend([mag_act.flatten(), mag_pred.flatten()])\n",
    "    err_vals.append(np.abs(mag_pred - mag_act).flatten())\n",
    "\n",
    "mag_all = np.concatenate(mag_vals)\n",
    "err_all = np.concatenate(err_vals)\n",
    "vmin_mag, vmax_mag = mag_all.min(), mag_all.max()\n",
    "vmin_err, vmax_err = 0.0, err_all.max()\n",
    "\n",
    "# --- 3) 5×3 그리드 플롯 ---\n",
    "fig, axes = plt.subplots(5, 3, figsize=(12, 10))\n",
    "plt.subplots_adjust(top=0.93, bottom=0.12, left=0.10, right=0.95,\n",
    "                    hspace=0.3, wspace=0.15)\n",
    "\n",
    "for row, idx in enumerate(sample_indices):\n",
    "    preds_norm, actual_norm = evaluate_sample_velocity(\n",
    "        model, test_branch, test_trunk, test_target, idx\n",
    "    )\n",
    "    preds_denorm  = inverse_normalize(preds_norm,  test_p[idx])\n",
    "    actual_denorm = inverse_normalize(actual_norm, test_p[idx])\n",
    "    mask = test_branch[idx].cpu().numpy()[0]\n",
    "    preds_corr  = apply_candidate_correction(preds_denorm,  mask)\n",
    "    actual_corr = apply_candidate_correction(actual_denorm, mask)\n",
    "    mag_pred = np.linalg.norm(preds_corr, axis=-1)\n",
    "    mag_act  = np.linalg.norm(actual_corr, axis=-1)\n",
    "    mag_err  = np.abs(mag_pred - mag_act)\n",
    "\n",
    "    # Column 0: Simulation |v|\n",
    "    ax0 = axes[row, 0]\n",
    "    im0 = ax0.imshow(mag_act, origin='lower',\n",
    "                     vmin=vmin_mag, vmax=vmax_mag,\n",
    "                     cmap='viridis')\n",
    "    ax0.set_ylabel(row_labels[row], rotation=0, labelpad=50, va='center')\n",
    "    if row == 0:\n",
    "        ax0.set_title(\"Simulation\")\n",
    "    ax0.set_xticks([]); ax0.set_yticks([])\n",
    "\n",
    "    # Column 1: DeepONet |v|\n",
    "    ax1 = axes[row, 1]\n",
    "    im1 = ax1.imshow(mag_pred, origin='lower',\n",
    "                     vmin=vmin_mag, vmax=vmax_mag,\n",
    "                     cmap='viridis')\n",
    "    if row == 0:\n",
    "        ax1.set_title(\"PRT-DeepONet\")\n",
    "    ax1.axis('off')\n",
    "\n",
    "    # Column 2: Absolute Error\n",
    "    ax2 = axes[row, 2]\n",
    "    im2 = ax2.imshow(mag_err, origin='lower',\n",
    "                     vmin=vmin_err, vmax=vmax_err,\n",
    "                     cmap='viridis')\n",
    "    if row == 0:\n",
    "        ax2.set_title(\"Abs Error\")\n",
    "    ax2.axis('off')\n",
    "\n",
    "# --- 4) 하단 컬러바 ---\n",
    "cbar_ax1 = fig.add_axes([0.1, 0.05, 0.55, 0.01])\n",
    "fig.colorbar(im0, cax=cbar_ax1, orientation='horizontal')\n",
    "cbar_ax2 = fig.add_axes([0.69, 0.05, 0.26, 0.01])\n",
    "fig.colorbar(im2, cax=cbar_ax2, orientation='horizontal')\n",
    "\n",
    "plt.savefig(\"vel_per.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564fdf8-fc70-4c67-9a07-53ee11f811ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "num_samples = len(test_branch)\n",
    "\n",
    "# 1) 유속 비율 계산\n",
    "vel_ratio = []\n",
    "for idx in range(num_samples):\n",
    "    sb = test_branch[idx:idx+1].to(device)\n",
    "    st = test_trunk[idx:idx+1].to(device)\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(sb, st).cpu().numpy()[0]    # (nx, ny, 2)\n",
    "\n",
    "    actual_norm = test_target[idx].cpu().numpy()\n",
    "    mask        = test_branch[idx].cpu().numpy()[0]\n",
    "\n",
    "    pred_mag   = np.sqrt(pred_norm[...,0]**2 + pred_norm[...,1]**2)\n",
    "    actual_mag = np.sqrt(actual_norm[...,0]**2 + actual_norm[...,1]**2)\n",
    "\n",
    "    pred_corr   = apply_candidate_correction(pred_mag, mask)\n",
    "    actual_corr = apply_candidate_correction(actual_mag, mask)\n",
    "    mean_pred   = pred_corr.mean()\n",
    "    mean_actual = actual_corr.mean()\n",
    "\n",
    "    vel_ratio.append(mean_actual / mean_pred if mean_pred != 0 else np.nan)\n",
    "\n",
    "# 2) 시각화\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(np.arange(num_samples), vel_ratio, alpha=0.5)\n",
    "plt.hlines(1, 0, num_samples-1, linestyles='--', color='red', label='Ratio=1')\n",
    "\n",
    "# y축 범위 고정\n",
    "plt.ylim(0.8, 1.2)\n",
    "\n",
    "plt.xlabel(\"Test Sample Index\")\n",
    "plt.ylabel(\"Actual / Predicted\")\n",
    "plt.title(\"Mean Velocity Magnitude Ratio\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "\n",
    "# SVG로 저장\n",
    "plt.savefig(\"velocity_ratio.svg\", format=\"svg\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f464f5-5eae-488f-8b0d-166e0af3b96d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "model.eval()\n",
    "num_samples = len(test_branch)\n",
    "\n",
    "vel_ratio = []\n",
    "for idx in range(num_samples):\n",
    "    sb = test_branch[idx:idx+1].to(device)\n",
    "    st = test_trunk[idx:idx+1].to(device)\n",
    "    with torch.no_grad():\n",
    "        pred_norm = model(sb, st).cpu().numpy()[0]    # (nx, ny, 2)\n",
    "    actual_norm = test_target[idx].cpu().numpy()\n",
    "    mask = test_branch[idx].cpu().numpy()[0]\n",
    "\n",
    "    pred_mag   = np.sqrt(pred_norm[...,0]**2 + pred_norm[...,1]**2)\n",
    "    actual_mag = np.sqrt(actual_norm[...,0]**2 + actual_norm[...,1]**2)\n",
    "\n",
    "    # 암석(mask==0)은 제외하고, 공극(mask==1)만 평균\n",
    "    mean_pred   = pred_mag[mask == 1].mean()\n",
    "    mean_actual = actual_mag[mask == 1].mean()\n",
    "\n",
    "    vel_ratio.append(mean_pred / mean_actual if mean_pred != 0 else np.nan)\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.scatter(np.arange(num_samples), vel_ratio, alpha=0.5)\n",
    "plt.hlines(1, 0, num_samples-1, linestyles='--', color='red', label='Ratio=1')\n",
    "plt.ylim(0.8, 1.2)\n",
    "plt.xlabel(\"Test Sample Index\")\n",
    "plt.ylabel(\"Predicted / Actual\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"velocity_ratio.svg\", format=\"svg\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f1b3bc-3c4d-4d94-9bfb-f36afc4b7e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
