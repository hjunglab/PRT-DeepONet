{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfdf48f3-ff75-4784-be9d-18735f7bd0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6ae659-3297-4cc4-95dc-bbef5173305e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 1. Reproducibility & Paths ======\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# === monod paths (kept as-is) ===\n",
    "DATA_DIR = \"/home/yehoon/npz/amv/monod/monod_data/\"\n",
    "MODEL_SAVE_PATH = \"./model/PRT_Monod/PRT_Monod.pt\"\n",
    "RESULT_SAVE_DIR = \"./model/PRT_Monod/PRT_Monod\"\n",
    "os.makedirs(RESULT_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "BATCH_SIZE = 25\n",
    "NUM_EPOCHS = 200\n",
    "LR = 1e-3\n",
    "NX, NY = 64, 148\n",
    "TRUNK_DIM = 4     # monod: (x, y, t_norm, dist_inlet)\n",
    "BRANCH2_DIM = 2   # (Pe, Da) for Monod setting\n",
    "OUT_DIM = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82f9686b-f08e-418c-aa75-c71f1e1ddc21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 2. Data Loader (kept paths exactly the same) ======\n",
    "def load_dataset():\n",
    "    # NOTE: os.path.join(DATA_DIR, <absolute_path>) ignores DATA_DIR by design.\n",
    "    # This mirrors your current code and will load from the absolute paths below.\n",
    "    train_dataset = torch.load(os.path.join(DATA_DIR, \"/home/yehoon/npz/model/PRT_monod/monod_train_dataset_trunk4.pt\"))\n",
    "    test_dataset  = torch.load(os.path.join(DATA_DIR, \"/home/yehoon/npz/model/PRT_monod/monod_test_dataset_trunk4.pt\"))\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d52f612c-6146-4379-a769-be2a1cf9e3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 3. Model Definition (paper-style names) ======\n",
    "class BranchCNN(nn.Module):\n",
    "    \"\"\"Geometry branch: CNN encoder for (1, H, W) binary pore image.\"\"\"\n",
    "    def __init__(self, in_channels, out_dim, num_blocks=5):  # monod often uses 5 blocks\n",
    "        super().__init__()\n",
    "        channels = [in_channels, 16, 32, 64, 128, 256][:num_blocks+1]\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers += [\n",
    "                nn.Conv2d(channels[i], channels[i+1], 3, 1, 1),\n",
    "                nn.SiLU(),\n",
    "                nn.AvgPool2d(2),\n",
    "            ]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        h, w = NX, NY\n",
    "        for _ in range(num_blocks):\n",
    "            h //= 2\n",
    "            w //= 2\n",
    "        self.fc = nn.Linear(channels[num_blocks]*h*w, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "class BranchFNN(nn.Module):\n",
    "    \"\"\"Parameter branch: FNN for (Pe, Da).\"\"\"\n",
    "    def __init__(self, in_dim=2, out_dim=128, hidden_dim=128, num_layers=3):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(in_dim, hidden_dim), nn.SiLU()]\n",
    "        for _ in range(num_layers-2):\n",
    "            layers += [nn.Linear(hidden_dim, hidden_dim), nn.SiLU()]\n",
    "        layers += [nn.Linear(hidden_dim, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Trunk(nn.Module):\n",
    "    \"\"\"Trunk network: FNN on (x, y, t_norm, dist_inlet).\"\"\"\n",
    "    def __init__(self, trunk_in_dim, out_dim, num_layers=8, width=128):\n",
    "        super().__init__()\n",
    "        layers = [nn.Linear(trunk_in_dim, width), nn.SiLU()]\n",
    "        for _ in range(num_layers-2):\n",
    "            layers += [nn.Linear(width, width), nn.SiLU()]\n",
    "        layers += [nn.Linear(width, out_dim)]\n",
    "        self.net = nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class PRT_DeepONet_Monod(nn.Module):\n",
    "    \"\"\"\n",
    "    Paper-style DeepONet:\n",
    "      y(x) = Î£_k  BranchCNN_k(geom) * BranchFNN_k(params) * Trunk_k(query) + b\n",
    "    where:\n",
    "      - geom   : (B,1,H,W)\n",
    "      - params : (B, BRANCH2_DIM)\n",
    "      - query  : (B, 1, L, TRUNK_DIM), L = H*W (or H*W*T for transient)\n",
    "    \"\"\"\n",
    "    def __init__(self, nx=64, ny=148, trunk_in_dim=4, out_dim=128, branch2_in_dim=2, cnn_blocks=5):\n",
    "        super().__init__()\n",
    "        self.nx, self.ny = nx, ny\n",
    "        self.branch_geom = BranchCNN(1, out_dim, num_blocks=cnn_blocks)\n",
    "        self.branch_param = BranchFNN(branch2_in_dim, out_dim, hidden_dim=128, num_layers=3)\n",
    "        self.trunk = Trunk(trunk_in_dim, out_dim, num_layers=8, width=128)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, branch1_input, branch2_input, trunk_input):\n",
    "        # branch1_input: (B,1,NX,NY)\n",
    "        # branch2_input: (B,BRANCH2_DIM)\n",
    "        # trunk_input  : (B, 1, L, TRUNK_DIM) or (B, L, TRUNK_DIM)\n",
    "        if trunk_input.ndim == 4:\n",
    "            trunk_input = trunk_input.squeeze(1)\n",
    "        B, L, D = trunk_input.shape\n",
    "\n",
    "        t = self.trunk(trunk_input)                                 # (B, L, C)\n",
    "        t = t.unsqueeze(1)                                          # (B, 1, L, C)\n",
    "        g = self.branch_geom(branch1_input).unsqueeze(1).unsqueeze(2)   # (B, 1, 1, C)\n",
    "        p = self.branch_param(branch2_input).unsqueeze(1).unsqueeze(2)  # (B, 1, 1, C)\n",
    "\n",
    "        out = (g * p * t).sum(-1) + self.bias                       # (B, 1, L)\n",
    "        out = out.view(B, self.nx, self.ny, 1)                      # (B, NX, NY, 1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf27ba3e-45c9-47f0-aa54-a80be9680d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 4. Training Utilities (same skeleton) ======\n",
    "def train_model(\n",
    "    model, train_dataset, test_dataset, num_epochs=1000, lr=0.001, batch_size=128, patience=15):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.HuberLoss(delta=1.0)\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "    class EarlyStopping:\n",
    "        def __init__(self, patience=15, delta=1e-5, verbose=True):\n",
    "            self.patience = patience\n",
    "            self.delta = delta\n",
    "            self.verbose = verbose\n",
    "            self.counter = 0\n",
    "            self.best_loss = None\n",
    "            self.early_stop = False\n",
    "            self.best_model_state = None\n",
    "        def __call__(self, val_loss, model):\n",
    "            if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "                self.best_loss = val_loss\n",
    "                self.counter = 0\n",
    "                self.best_model_state = copy.deepcopy(model.state_dict())\n",
    "                if self.verbose:\n",
    "                    print(f\"Validation loss decreased. New best loss: {val_loss:.6f}\")\n",
    "            else:\n",
    "                self.counter += 1\n",
    "                if self.verbose:\n",
    "                    print(f\"No improvement in validation loss. Counter: {self.counter}/{self.patience}\")\n",
    "                if self.counter >= self.patience:\n",
    "                    self.early_stop = True\n",
    "\n",
    "    early_stopping = EarlyStopping(patience=15, delta=1e-5, verbose=True)\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        # --- Training ---\n",
    "        model.train()\n",
    "        running_train_loss = 0.0\n",
    "        for batch in train_loader:\n",
    "            batch_branch1, batch_branch2, batch_trunk, batch_target = [b.to(device) for b in batch]\n",
    "            optimizer.zero_grad()\n",
    "            with torch.cuda.amp.autocast():\n",
    "                preds = model(batch_branch1, batch_branch2, batch_trunk)\n",
    "                loss = criterion(preds, batch_target)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            running_train_loss += loss.item()\n",
    "        avg_train_loss = running_train_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "\n",
    "        # --- Validation ---\n",
    "        model.eval()\n",
    "        running_test_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch in test_loader:\n",
    "                batch_branch1, batch_branch2, batch_trunk, batch_target = [b.to(device) for b in batch]\n",
    "                with torch.cuda.amp.autocast():\n",
    "                    preds = model(batch_branch1, batch_branch2, batch_trunk)\n",
    "                    loss = criterion(preds, batch_target)\n",
    "                running_test_loss += loss.item()\n",
    "        avg_test_loss = running_test_loss / len(test_loader)\n",
    "        test_losses.append(avg_test_loss)\n",
    "\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}] Train: {avg_train_loss:.6f} | Test: {avg_test_loss:.6f}\")\n",
    "\n",
    "        early_stopping(avg_test_loss, model)\n",
    "        if early_stopping.early_stop:\n",
    "            print(\"Early stopping triggered. Restoring best model state.\")\n",
    "            model.load_state_dict(early_stopping.best_model_state)\n",
    "            break\n",
    "\n",
    "    return train_losses, test_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73211127-5d2d-4fbb-94b8-5c2a2eb8ccf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====== 5. Evaluation Example (same skeleton) ======\n",
    "def evaluate(model, test_dataset, num_samples=5):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    for idx in range(min(num_samples, len(test_dataset))):\n",
    "        b1, b2, trunk, y_true = [x[idx:idx+1].to(device) for x in test_dataset.tensors]\n",
    "        with torch.no_grad():\n",
    "            y_pred = model(b1, b2, trunk)\n",
    "        y_true_np = y_true.cpu().numpy()[0, ..., 0]\n",
    "        y_pred_np = y_pred.cpu().numpy()[0, ..., 0]\n",
    "        plt.figure(figsize=(8,3))\n",
    "        plt.subplot(1,2,1); plt.imshow(y_true_np, cmap='viridis'); plt.title('Ground Truth'); plt.axis('off')\n",
    "        plt.subplot(1,2,2); plt.imshow(y_pred_np, cmap='viridis'); plt.title('Prediction');  plt.axis('off')\n",
    "        plt.suptitle(f\"Sample #{idx}\")\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19059137-3d45-4ed2-93e2-e7736d341ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/200] Train: 0.001885 | Test: 0.001330\n",
      "Validation loss decreased. New best loss: 0.001330\n",
      "Epoch [2/200] Train: 0.001039 | Test: 0.001186\n",
      "Validation loss decreased. New best loss: 0.001186\n",
      "Epoch [3/200] Train: 0.000420 | Test: 0.001122\n",
      "Validation loss decreased. New best loss: 0.001122\n",
      "Epoch [4/200] Train: 0.000288 | Test: 0.001095\n",
      "Validation loss decreased. New best loss: 0.001095\n",
      "Epoch [5/200] Train: 0.000235 | Test: 0.001044\n",
      "Validation loss decreased. New best loss: 0.001044\n",
      "Epoch [6/200] Train: 0.000207 | Test: 0.001065\n",
      "No improvement in validation loss. Counter: 1/15\n",
      "Epoch [7/200] Train: 0.000189 | Test: 0.001040\n",
      "No improvement in validation loss. Counter: 2/15\n",
      "Epoch [8/200] Train: 0.000175 | Test: 0.001035\n",
      "No improvement in validation loss. Counter: 3/15\n",
      "Epoch [9/200] Train: 0.000167 | Test: 0.001026\n",
      "Validation loss decreased. New best loss: 0.001026\n"
     ]
    }
   ],
   "source": [
    "# ====== 6. Main Entry (same skeleton) ======\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Load Data\n",
    "    train_dataset, test_dataset = load_dataset()\n",
    "    # Shapes (for reference):\n",
    "    # train_dataset.tensors[0]: (N, 1, 64, 148)        # geometry\n",
    "    # train_dataset.tensors[1]: (N, 2)                 # (Pe, Da)\n",
    "    # train_dataset.tensors[2]: (N, 9472, 4)           # (x, y, t_norm, dist_inlet)\n",
    "    # train_dataset.tensors[3]: (N, 64, 148, 1)        # target\n",
    "\n",
    "    # 2) Build Model (paper-style names)\n",
    "    model = PRT_DeepONet_Monod(\n",
    "        nx=NX, ny=NY, trunk_in_dim=TRUNK_DIM, out_dim=OUT_DIM,\n",
    "        branch2_in_dim=BRANCH2_DIM, cnn_blocks=5\n",
    "    )\n",
    "\n",
    "    # 3) Train\n",
    "    train_losses, test_losses = train_model(\n",
    "        model, train_dataset, test_dataset,\n",
    "        num_epochs=NUM_EPOCHS, lr=LR, batch_size=BATCH_SIZE\n",
    "    )\n",
    "\n",
    "    # 4) Evaluate\n",
    "    evaluate(model, test_dataset)\n",
    "\n",
    "    # 5) Save\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    # 6) (Optional) Plot losses\n",
    "    plt.figure()\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(test_losses, label=\"Test\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28698e2d-f327-4743-b0b4-a1e26a89109e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
