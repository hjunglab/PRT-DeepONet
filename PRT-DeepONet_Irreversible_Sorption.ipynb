{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8dc94523-aee3-42f3-9339-4a553e3cbad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nPRT-DeepONet_irreversible_sorption (Steady-State, GDF-only, Minimal Runner)\\n- Trunk input: [x, y, GDF_inlet_norm]\\n- Uses ONLY two prebuilt datasets:\\n    Steady_train_dataset.pt\\n    Steady_test_dataset.pt\\n- All paths are absolute by default (modify where marked)\\n\\nPlaceholders to change:\\n    >>> CHANGE HERE: use your own absolute path\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "PRT-DeepONet_irreversible_sorption (Steady-State, GDF-only, Minimal Runner)\n",
    "- Trunk input: [x, y, GDF_inlet_norm]\n",
    "- Uses ONLY two prebuilt datasets:\n",
    "    Steady_train_dataset.pt\n",
    "    Steady_test_dataset.pt\n",
    "- All paths are absolute by default (modify where marked)\n",
    "\n",
    "Placeholders to change:\n",
    "    >>> CHANGE HERE: use your own absolute path\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08013c17-47d1-4ba5-840d-565beaca5c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 0) Imports & deterministic setup\n",
    "# ===============================\n",
    "import os\n",
    "import copy\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8746b3f4-5b43-49a5-a296-9a40af12ff4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 1) Absolute paths (edit here)\n",
    "# ===============================\n",
    "# >>> CHANGE HERE: absolute paths to your saved datasets\n",
    "TRAIN_DATASET_PATH = \"/home/yehoon/npz/model/Steady_train_dataset.pt\"\n",
    "TEST_DATASET_PATH  = \"/home/yehoon/npz/model/Steady_test_dataset.pt\"\n",
    "\n",
    "# >>> CHANGE HERE: output paths for model and results\n",
    "MODEL_SAVE_PATH    = \"/home/yehoon/npz/model/PRT_Steady_state/PRT-DeepONet_irreversible_sorption.pt\"\n",
    "RESULT_DIR         = \"/home/yehoon/npz/model/PRT_Steady_state/PRT_Steady_result\"\n",
    "\n",
    "os.makedirs(os.path.dirname(MODEL_SAVE_PATH), exist_ok=True)\n",
    "os.makedirs(RESULT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7c6bff78-2bea-49d2-9432-de65d487bd7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Grid size detected: H=64, W=148\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 2) Load datasets & sanity check\n",
    "# ===============================\n",
    "if not (os.path.exists(TRAIN_DATASET_PATH) and os.path.exists(TEST_DATASET_PATH)):\n",
    "    raise FileNotFoundError(\n",
    "        \"Dataset files not found.\\n\"\n",
    "        f\"- {TRAIN_DATASET_PATH}\\n- {TEST_DATASET_PATH}\"\n",
    "    )\n",
    "\n",
    "train_dataset = torch.load(TRAIN_DATASET_PATH, map_location=\"cpu\")\n",
    "test_dataset  = torch.load(TEST_DATASET_PATH,  map_location=\"cpu\")\n",
    "\n",
    "def _peek_shapes(ds, name=\"dataset\"):\n",
    "    b1, b2, trk, tgt = ds.tensors\n",
    "    assert b1.ndim == 4 and b1.shape[1] == 1, f\"{name}: branch1 expected (N,1,H,W)\"\n",
    "    assert b2.ndim == 2 and b2.shape[1] == 2, f\"{name}: branch2 expected (N,2)\"\n",
    "    assert trk.ndim == 4 and trk.shape[1] == 1 and trk.shape[-1] == 3, f\"{name}: trunk expected (N,1,L,3)\"\n",
    "    assert tgt.ndim == 4 and tgt.shape[-1] == 1, f\"{name}: target expected (N,H,W,1)\"\n",
    "    return b1.shape[2], b1.shape[3]\n",
    "\n",
    "H, W = _peek_shapes(test_dataset, \"test_dataset\")\n",
    "print(f\"[INFO] Grid size detected: H={H}, W={W}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d96238c9-f4ad-4ad8-9ee3-e0a07f9a7bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 3) Network components\n",
    "# ===============================\n",
    "class BranchCNN(nn.Module):\n",
    "    \"\"\"Branch network for geometry (CNN)\"\"\"\n",
    "    def __init__(self, in_ch=1, out_dim=128, num_blocks=5, nx=64, ny=148):\n",
    "        super().__init__()\n",
    "        chs = [in_ch, 16, 32, 64, 128, 256][:num_blocks+1]\n",
    "        layers = []\n",
    "        for i in range(num_blocks):\n",
    "            layers += [\n",
    "                nn.Conv2d(chs[i], chs[i+1], kernel_size=3, stride=1, padding=1),\n",
    "                nn.SiLU(),\n",
    "                nn.AvgPool2d(2),\n",
    "            ]\n",
    "        self.features = nn.Sequential(*layers)\n",
    "        h, w = nx, ny\n",
    "        for _ in range(num_blocks):\n",
    "            h //= 2; w //= 2\n",
    "        self.fc = nn.Linear(chs[num_blocks]*h*w, out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)             # (B,C,h,w)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        return self.fc(x)                 # (B,out_dim)\n",
    "\n",
    "class BranchFNN(nn.Module):\n",
    "    \"\"\"Branch network for parameters (Pe, DaA)\"\"\"\n",
    "    def __init__(self, in_dim=2, out_dim=128, hidden=128, layers=3):\n",
    "        super().__init__()\n",
    "        L = [nn.Linear(in_dim, hidden), nn.SiLU()]\n",
    "        for _ in range(layers-2):\n",
    "            L += [nn.Linear(hidden, hidden), nn.SiLU()]\n",
    "        L += [nn.Linear(hidden, out_dim)]\n",
    "        self.net = nn.Sequential(*L)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class Trunk(nn.Module):\n",
    "    \"\"\"Trunk network for coordinates (x, y, GDF_inlet_norm)\"\"\"\n",
    "    def __init__(self, in_dim=3, out_dim=128, layers=8, width=128):\n",
    "        super().__init__()\n",
    "        L = [nn.Linear(in_dim, width), nn.SiLU()]\n",
    "        for _ in range(layers-2):\n",
    "            L += [nn.Linear(width, width), nn.SiLU()]\n",
    "        L += [nn.Linear(width, out_dim)]\n",
    "        self.net = nn.Sequential(*L)\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class PRT_DeepONet_irreversible_sorption(nn.Module):\n",
    "    \"\"\"y(x) = sum_k B_geom_k * B_param_k * T_k(x) + b\"\"\"\n",
    "    def __init__(self, nx=64, ny=148, out_dim=128):\n",
    "        super().__init__()\n",
    "        self.nx, self.ny = nx, ny\n",
    "        self.branch_geom = BranchCNN(1, out_dim, num_blocks=5, nx=nx, ny=ny)\n",
    "        self.branch_param = BranchFNN(2, out_dim, hidden=128, layers=3)\n",
    "        self.trunk = Trunk(in_dim=3, out_dim=out_dim, layers=8, width=128)\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "\n",
    "    def forward(self, b1, b2, trunk_in):\n",
    "        B, _, L, D = trunk_in.shape\n",
    "        t = self.trunk(trunk_in.view(B*L, D)).view(B, L, -1).unsqueeze(1)   # (B,1,L,C)\n",
    "        g = self.branch_geom(b1).unsqueeze(1).unsqueeze(2)                  # (B,1,1,C)\n",
    "        p = self.branch_param(b2).unsqueeze(1).unsqueeze(2)                 # (B,1,1,C)\n",
    "        y = (g * p * t).sum(-1) + self.bias                                 # (B,1,L)\n",
    "        return y.view(B, self.nx, self.ny, 1)                               # (B,H,W,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c53806b-212e-4c88-b547-2188af89bc5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===============================\n",
    "# 4) Training & evaluation\n",
    "# ===============================\n",
    "def train_model(model, train_dataset, test_dataset, num_epochs=200, lr=1e-3, batch_size=25, patience=15):\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    test_loader  = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "    criterion = nn.HuberLoss(delta=1.0)\n",
    "    scaler = torch.cuda.amp.GradScaler(enabled=torch.cuda.is_available())\n",
    "\n",
    "    best_loss = float(\"inf\")\n",
    "    best_state = None\n",
    "    counter = 0\n",
    "    train_losses, test_losses = [], []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        tr_loss = 0.0\n",
    "        for b1, b2, trk, tgt in train_loader:\n",
    "            b1, b2, trk, tgt = b1.to(device), b2.to(device), trk.to(device), tgt.to(device)\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "                pred = model(b1, b2, trk)\n",
    "                loss = criterion(pred, tgt)\n",
    "            scaler.scale(loss).backward()\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            tr_loss += loss.item()\n",
    "        avg_tr = tr_loss / len(train_loader)\n",
    "        train_losses.append(avg_tr)\n",
    "\n",
    "        # validation\n",
    "        model.eval()\n",
    "        te_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for b1, b2, trk, tgt in test_loader:\n",
    "                b1, b2, trk, tgt = b1.to(device), b2.to(device), trk.to(device), tgt.to(device)\n",
    "                with torch.autocast(device_type=\"cuda\", dtype=torch.float16, enabled=torch.cuda.is_available()):\n",
    "                    pred = model(b1, b2, trk)\n",
    "                    loss = criterion(pred, tgt)\n",
    "                te_loss += loss.item()\n",
    "        avg_te = te_loss / len(test_loader)\n",
    "        test_losses.append(avg_te)\n",
    "\n",
    "        print(f\"[{epoch+1:03d}] Train {avg_tr:.6f} | Test {avg_te:.6f}\")\n",
    "\n",
    "        if avg_te < best_loss - 1e-5:\n",
    "            best_loss = avg_te\n",
    "            best_state = copy.deepcopy(model.state_dict())\n",
    "            counter = 0\n",
    "        else:\n",
    "            counter += 1\n",
    "            if counter >= patience:\n",
    "                print(\"Early stopping.\")\n",
    "                break\n",
    "\n",
    "    if best_state is not None:\n",
    "        model.load_state_dict(best_state)\n",
    "    torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "    print(f\"[SAVE] Model saved to {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    # loss curve\n",
    "    plt.plot(train_losses, label=\"Train\")\n",
    "    plt.plot(test_losses, label=\"Test\")\n",
    "    plt.xlabel(\"Epoch\"); plt.ylabel(\"Loss\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    plt.savefig(os.path.join(RESULT_DIR, \"loss_curve.png\"), dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e515f412-ef9a-4c1d-9c9b-1ba246258cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[001] Train 0.004099 | Test 0.001239\n",
      "[002] Train 0.001160 | Test 0.001002\n",
      "[003] Train 0.001007 | Test 0.000855\n",
      "[004] Train 0.000894 | Test 0.000848\n",
      "[005] Train 0.000856 | Test 0.000840\n",
      "[006] Train 0.000821 | Test 0.000839\n",
      "[007] Train 0.000783 | Test 0.000753\n",
      "[008] Train 0.000772 | Test 0.000726\n",
      "[009] Train 0.000719 | Test 0.000787\n",
      "[010] Train 0.000719 | Test 0.000709\n",
      "[011] Train 0.000664 | Test 0.000714\n",
      "[012] Train 0.000585 | Test 0.000606\n",
      "[013] Train 0.000536 | Test 0.000596\n",
      "[014] Train 0.000487 | Test 0.000559\n",
      "[015] Train 0.000455 | Test 0.000574\n",
      "[016] Train 0.000410 | Test 0.000581\n",
      "[017] Train 0.000361 | Test 0.000560\n",
      "[018] Train 0.000326 | Test 0.000551\n",
      "[019] Train 0.000293 | Test 0.000537\n",
      "[020] Train 0.000270 | Test 0.000569\n",
      "[021] Train 0.000246 | Test 0.000565\n",
      "[022] Train 0.000228 | Test 0.000567\n",
      "[023] Train 0.000219 | Test 0.000575\n",
      "[024] Train 0.000204 | Test 0.000540\n",
      "[025] Train 0.000192 | Test 0.000567\n",
      "[026] Train 0.000181 | Test 0.000537\n",
      "[027] Train 0.000175 | Test 0.000534\n",
      "[028] Train 0.000169 | Test 0.000568\n",
      "[029] Train 0.000161 | Test 0.000555\n",
      "[030] Train 0.000156 | Test 0.000521\n",
      "[031] Train 0.000150 | Test 0.000531\n",
      "[032] Train 0.000147 | Test 0.000520\n",
      "[033] Train 0.000140 | Test 0.000566\n",
      "[034] Train 0.000138 | Test 0.000575\n",
      "[035] Train 0.000136 | Test 0.000539\n",
      "[036] Train 0.000130 | Test 0.000531\n",
      "[037] Train 0.000130 | Test 0.000558\n",
      "[038] Train 0.000127 | Test 0.000522\n",
      "[039] Train 0.000120 | Test 0.000514\n",
      "[040] Train 0.000120 | Test 0.000538\n",
      "[041] Train 0.000120 | Test 0.000533\n",
      "[042] Train 0.000116 | Test 0.000518\n",
      "[043] Train 0.000111 | Test 0.000525\n",
      "[044] Train 0.000114 | Test 0.000519\n",
      "[045] Train 0.000112 | Test 0.000556\n",
      "Early stopping.\n",
      "[SAVE] Model saved to /home/yehoon/npz/model/PRT_Steady_state/PRT-DeepONet_irreversible_sorption.pt\n",
      "[DONE]\n"
     ]
    }
   ],
   "source": [
    "# ===============================\n",
    "# 5) Run training\n",
    "# ===============================\n",
    "if __name__ == \"__main__\":\n",
    "    model = PRT_DeepONet_irreversible_sorption(nx=H, ny=W, out_dim=128)\n",
    "    train_model(model, train_dataset, test_dataset,\n",
    "                num_epochs=200, lr=1e-3, batch_size=25, patience=15)\n",
    "    print(\"[DONE]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9c02816-b37c-45cd-b455-a55227c9341b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
